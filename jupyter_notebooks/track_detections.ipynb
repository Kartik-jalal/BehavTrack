{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ffprobe import FFProbe\n",
    "import os\n",
    "import json\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPointInBBox(x, y, x1, y1, x2, y2):\n",
    "  return (\n",
    "    x >= x1 and x <= x2 and\n",
    "    y >= y1 and y <= y2\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_txt_to_annotation_json(\n",
    "    txt_path, \n",
    "    image_filename,   # \"image_filename.jpg\"\n",
    "    image_width, \n",
    "    image_height,\n",
    "    mAnnotated_flag,\n",
    "    visiblePercentage,\n",
    "    keypoint_names=None,\n",
    "    tracked=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads a YOLO-like .txt (with bbox + 4 keypoints in normalized coords),\n",
    "    and returns a dictionary in the original annotation style:\n",
    "\n",
    "    {\n",
    "      \"image_filename\": [\n",
    "        \"Tracking number\": {\n",
    "          \"bbox\": {\"x1\":..., \"y1\":..., \"x2\":..., \"y2\":...},\n",
    "          \"keypoints\": {\n",
    "            \"nose\":  [...],\n",
    "            \"earL\":  [...],\n",
    "            \"earR\":  [...],\n",
    "            \"tailB\": [...]\n",
    "          }\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if keypoint_names is None:\n",
    "            # You can change the order or number of keypoints as needed:\n",
    "            keypoint_names = [\"nose\", \"earL\", \"earR\", \"tailB\"]\n",
    "\n",
    "        annotations = {image_filename: []}\n",
    "        if tracked:\n",
    "            annotations = {image_filename: {}}\n",
    "\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            tokens = line.split()\n",
    "            # The first 5 tokens are class_id, x_center, y_center, w, h\n",
    "            class_id    = int(tokens[0])\n",
    "            x_center_n  = float(tokens[1])\n",
    "            y_center_n  = float(tokens[2])\n",
    "            w_n         = float(tokens[3])\n",
    "            h_n         = float(tokens[4])\n",
    "\n",
    "            # Denormalize bounding box\n",
    "            x_center = x_center_n * image_width\n",
    "            y_center = y_center_n * image_height\n",
    "            w        = w_n * image_width\n",
    "            h        = h_n * image_height\n",
    "\n",
    "            x1 = x_center - w / 2\n",
    "            y1 = y_center - h / 2\n",
    "            x2 = x_center + w / 2\n",
    "            y2 = y_center + h / 2\n",
    "\n",
    "            if (x1 == x2 or y1 == y2):\n",
    "                continue\n",
    "\n",
    "            # Next tokens: each keypoint has x_kpt_n, y_kpt_n, v_kpt\n",
    "            # For 4 keypoints, that's 12 tokens, starting at index = 5\n",
    "            keypoints_dict = {}\n",
    "            num_kpts = len(keypoint_names)\n",
    "\n",
    "            # i.e. for 4 keypoints, range(4) => 0..3\n",
    "            for i in range(num_kpts):\n",
    "                x_kpt_n = float(tokens[5 + 3*i])\n",
    "                y_kpt_n = float(tokens[5 + 3*i + 1])\n",
    "                v_kpt   = float(tokens[5 + 3*i + 2])\n",
    "\n",
    "                # denormalize\n",
    "                x_kpt = x_kpt_n * image_width\n",
    "                y_kpt = y_kpt_n * image_height\n",
    "\n",
    "                if not(isPointInBBox(x_kpt, y_kpt, x1, y1, x2, y2)):\n",
    "                    continue\n",
    "                \n",
    "                kpt_name = keypoint_names[i]\n",
    "\n",
    "                keypoints_dict[kpt_name] = [x_kpt, y_kpt, 2 if v_kpt > visiblePercentage else 1]           \n",
    "\n",
    "            annotation = {\n",
    "                \"bbox\": {\n",
    "                    \"x1\": x1,\n",
    "                    \"y1\": y1,\n",
    "                    \"x2\": x2,\n",
    "                    \"y2\": y2\n",
    "                },\n",
    "                \"keypoints\": keypoints_dict,\n",
    "                \"mAnnotated\": mAnnotated_flag\n",
    "            }\n",
    "\n",
    "            if tracked:\n",
    "                tracking_id = int(tokens[17])\n",
    "                annotations[image_filename].update({\n",
    "                    f'{tracking_id}' : annotation\n",
    "                })\n",
    "            else:\n",
    "                annotations[image_filename].append(annotation)\n",
    "\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error while processing the text file\\n\\t{txt_path}\\n\\t\\tError - {error}\")\n",
    "        return {}, False\n",
    "\n",
    "\n",
    "    return annotations, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_resolution(filename):\n",
    "    \"\"\"\n",
    "    Returns (width, height) for the first video stream found in `filename`.\n",
    "    \"\"\"\n",
    "    metadata = FFProbe(filename)\n",
    "    for stream in metadata.streams:\n",
    "        if stream.is_video():\n",
    "            return (int(stream.width), int(stream.height))\n",
    "        \n",
    "    return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nOf_frames(filename):\n",
    "    metadata = FFProbe(filename)\n",
    "    for stream in metadata.streams:\n",
    "        if stream.is_video():\n",
    "            return int(stream.nb_frames)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata(output_dir, metadata_filename, metadata):\n",
    "    metadata_outFilePath = os.path.join(output_dir, metadata_filename)\n",
    "\n",
    "    with open(metadata_outFilePath, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(source_dir, metadata_filename):\n",
    "    metadata_filePath = os.path.join(source_dir, metadata_filename)\n",
    "\n",
    "    with open(metadata_filePath, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bBox_xyxyc(bBox):\n",
    "\n",
    "    c_x = 0.5*(bBox['x1'] + bBox['x2'])\n",
    "    c_y = 0.5*(bBox['y1'] + bBox['y2'])\n",
    "    \n",
    "    return (bBox['x1'], bBox['y1'], bBox['x2'], bBox['y2'], c_x, c_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints_xyxyc(keypoints, bBox, scale_factor=0.02):\n",
    "    '''\n",
    "    input: {\n",
    "        'nose' : [x, y, visible_flag],\n",
    "        'earL' : [x, y, visible_flag],\n",
    "        'earR' : [x, y, visible_flag],\n",
    "        'tailB' : [x, y, visible_flag]\n",
    "    }\n",
    "    output: {\n",
    "        'nose' : (x1, y1, x2, y2, c_x, c_y),\n",
    "        'earL' : (x1, y1, x2, y2, c_x, c_y),\n",
    "        'earR' : (x1, y1, x2, y2, c_x, c_y),\n",
    "        'tailB' : (x1, y1, x2, y2, c_x, c_y)\n",
    "    }\n",
    "    '''\n",
    "    keypoints_xyxyc = {}\n",
    "\n",
    "    bBox_w = max(0., bBox['x2'] - bBox['x1'])\n",
    "    bBox_h = max(0., bBox['y2'] - bBox['y1'])\n",
    "\n",
    "    keypoint_bBox_w = scale_factor * bBox_w\n",
    "    keypoint_bBox_h = scale_factor * bBox_h\n",
    "\n",
    "    for keypoint, coordinates in keypoints.items():\n",
    "        x1 = coordinates[0] - (keypoint_bBox_w/2)\n",
    "        y1 = coordinates[1] - (keypoint_bBox_h/2)\n",
    "        x2 = coordinates[0] + (keypoint_bBox_w/2)\n",
    "        y2 = coordinates[1] + (keypoint_bBox_h/2)\n",
    "\n",
    "        keypoints_xyxyc[keypoint] = (\n",
    "            x1, y1, x2, y2, coordinates[0], coordinates[1]\n",
    "        )\n",
    "\n",
    "    return keypoints_xyxyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(b1, b2):\n",
    "    \"\"\"\n",
    "    Compute IoU of two bounding boxes in (x1, y1, x2, y2) format.\n",
    "      b1, b2 = (x1, y1, x2, y2) in the same coordinate system.\n",
    "    \"\"\"\n",
    "    # Intersection\n",
    "    ix1 = max(b1[0], b2[0])\n",
    "    iy1 = max(b1[1], b2[1])\n",
    "    ix2 = min(b1[2], b2[2])\n",
    "    iy2 = min(b1[3], b2[3])\n",
    "\n",
    "    iw = max(0., ix2 - ix1)\n",
    "    ih = max(0., iy2 - iy1)\n",
    "    inter = iw * ih\n",
    "\n",
    "    # Union\n",
    "    area1 = (b1[2] - b1[0]) * (b1[3] - b1[1])\n",
    "    area2 = (b2[2] - b2[0]) * (b2[3] - b2[1])\n",
    "    union = area1 + area2 - inter\n",
    "    \n",
    "    if union < 1e-9:\n",
    "        return 0.\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_distance(b1, b2, abs_w, abs_h):\n",
    "    \"\"\"\n",
    "    Euclidean distance between centers of two bounding boxes\n",
    "    in (x1, y1, x2, y2) format.\n",
    "    \"\"\"\n",
    "    c1_x, c1_y = b1[4], b1[5]\n",
    "    c2_x, c2_y = b2[4], b2[5]\n",
    "\n",
    "    dx = abs(c1_x - c2_x)\n",
    "    dy = abs(c1_y - c2_y)\n",
    "\n",
    "    dx_norm = dx / abs_w if abs_w != 0 else dx\n",
    "    dy_norm = dy / abs_h if abs_h != 0 else dy\n",
    "\n",
    "    norm_distance = (dx_norm**2 + dy_norm**2) ** 0.5\n",
    "    \n",
    "    img_diagonal = (abs_w**2 + abs_h**2) ** 0.5\n",
    "    \n",
    "    return norm_distance/img_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_keypoints(track, det):\n",
    "    keypoints_present = 0\n",
    "\n",
    "    iou = 0\n",
    "    for keypoint, coordinates in track.items():\n",
    "        if not (keypoint in det):\n",
    "            continue\n",
    "        \n",
    "        iou += get_iou(coordinates, det[keypoint])\n",
    "        keypoints_present += 1\n",
    "\n",
    "    if keypoints_present == 0:\n",
    "        return 0\n",
    "\n",
    "    avg_iou = iou / keypoints_present\n",
    "    \n",
    "    return (keypoints_present/4) * avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_distance_keypoints(track, det, abs_w, abs_h, penalty_per_missing=10):\n",
    "    keypoints_present = 0\n",
    "\n",
    "    center_distance = 0\n",
    "    for keypoint, coordinates in track.items():\n",
    "        if not (keypoint in det):\n",
    "            continue\n",
    "        \n",
    "        # get and add the Euclidean distance\n",
    "        center_distance += get_center_distance(coordinates, det[keypoint], abs_w, abs_h)\n",
    "        keypoints_present += 1\n",
    "\n",
    "    missing_keypoints = 4 - keypoints_present\n",
    "    if keypoints_present > 0:\n",
    "        avg_distance = center_distance / keypoints_present\n",
    "    else:\n",
    "        # If no keypoints detected, return infinite\n",
    "        return 1\n",
    "\n",
    "    # Add penalty for missing keypoints\n",
    "    # total_score = avg_distance + missing_keypoints / penalty_per_missing\n",
    "    total_score = (avg_distance + missing_keypoints)/ (missing_keypoints+1)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(track, detection, scale_factor, penalty_per_missing, abs_w, abs_h, alpha=0.5, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "     lower cost => better match.\n",
    "    \"\"\"\n",
    "    track_bBox_xyxyc = get_bBox_xyxyc(track['bbox'])\n",
    "    det_bBox_xyxyc   = get_bBox_xyxyc(detection['bbox'])\n",
    "\n",
    "    iou_bBox_val   = get_iou(track_bBox_xyxyc, det_bBox_xyxyc)\n",
    "    cdist_bBox_val = get_center_distance(track_bBox_xyxyc, det_bBox_xyxyc, abs_w, abs_h)\n",
    "\n",
    "\n",
    "    track_keypoints_xyxyc = get_keypoints_xyxyc(track['keypoints'], track['bbox'], scale_factor)\n",
    "    det_keypoint_xyxyc   = get_keypoints_xyxyc(detection['keypoints'], detection['bbox'], scale_factor)\n",
    "\n",
    "    iou_keypoints_val = iou_keypoints(track_keypoints_xyxyc, det_keypoint_xyxyc)\n",
    "    cdist_keypoints_val = center_distance_keypoints(track_keypoints_xyxyc, det_keypoint_xyxyc,  abs_w, abs_h, penalty_per_missing)\n",
    "\n",
    "\n",
    "    cdist_cost =  (1-alpha)*((cdist_bBox_val + cdist_keypoints_val)/2)\n",
    "    iou_cost = alpha * ((iou_bBox_val + iou_keypoints_val)/2)\n",
    "    \n",
    "\n",
    "    return (cdist_cost - iou_cost)/(cdist_cost + iou_cost + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(vid_name, nOf_fames, detections, framesSkip_limit, scale_factor, penalty_per_missing,  abs_w, abs_h, alpha, epsilon, cost_threshold=0.5, releaseId_atValue=16, printing=False):\n",
    "    currentFrame_index = 1\n",
    "\n",
    "    # the dict helps in keeping info of\n",
    "    # stuck ids because of higher cost and\n",
    "    # can be realse if the val[1] (stuck time)\n",
    "    # has reached the releaseId_atValue\n",
    "    stuck_ids = {\n",
    "        '1' : (False, 0),\n",
    "        '2' : (False, 0),\n",
    "        '3' : (False, 0),\n",
    "        '4' : (False, 0),\n",
    "        '5' : (False, 0)\n",
    "    }\n",
    "\n",
    "    while currentFrame_index < nOf_fames:\n",
    "        # next frame\n",
    "        nextFrame_index = currentFrame_index + 1\n",
    "\n",
    "        # check if the next frame index is valid or not\n",
    "        index_flag = f\"{nextFrame_index}\" in detections\n",
    "        index_jump = False\n",
    "        # until we find a valid next frame\n",
    "        while not index_flag:\n",
    "            if nextFrame_index == len(detections):\n",
    "                break       \n",
    "            \n",
    "            print(f\"Missing index {nextFrame_index} - {vid_name}\")\n",
    "            nextFrame_index += 1\n",
    "            index_flag = f\"{nextFrame_index}\" in detections\n",
    "            index_jump = True\n",
    "        # if no valid next frame found\n",
    "        if not index_flag:\n",
    "            break\n",
    "        # if there was a next frame index skip and the skip was of framesSkip_limit frames, jump to \n",
    "        # that index as the current index\n",
    "        if index_jump and (nextFrame_index - currentFrame_index > framesSkip_limit):\n",
    "            currentFrame_index = nextFrame_index\n",
    "            # the valid mouse ids a frame can have\n",
    "            available_ids = ['1', '2', '3', '4', '5']\n",
    "            # a temporary holder to hold the annotations\n",
    "            # in the right ids\n",
    "            temp_holder = {}\n",
    "            # for every annotations change their id to a valid id\n",
    "            for _, currentFrame_mouseAnnotations in detections[f'{currentFrame_index}'].items():\n",
    "                temp_holder[available_ids.pop()] = currentFrame_mouseAnnotations\n",
    "            \n",
    "            # update the annotations for the skip frames\n",
    "            detections[f'{currentFrame_index}'] = temp_holder\n",
    "            # skip to that frame\n",
    "            continue\n",
    "        \n",
    "        # To store if the current Frame have valid mouse Ids \n",
    "        # and if they exist in the next frame.\n",
    "        # mouse_ID : (currentFrame_exist, nextFrame_exist) \n",
    "        valid_mouseId_presence = {\n",
    "            '1' : (False, False),\n",
    "            '2' : (False, False),\n",
    "            '3' : (False, False),\n",
    "            '4' : (False, False),\n",
    "            '5' : (False, False),\n",
    "        }\n",
    "        for currentFrame_mouseId, _ in detections[f'{currentFrame_index}'].items():\n",
    "            valid_mouseId_presence[currentFrame_mouseId] = (\n",
    "                True, (currentFrame_mouseId in detections[f'{nextFrame_index}'])\n",
    "            )\n",
    "\n",
    "        # To store new mouse Ids appeared in the next frame\n",
    "        new_nextFrame_mouseIds = []\n",
    "        for nextFrame_mouseId, _ in detections[f'{nextFrame_index}'].items():\n",
    "            if nextFrame_mouseId in detections[f'{currentFrame_index}']:\n",
    "                continue\n",
    "\n",
    "            new_nextFrame_mouseIds.append(nextFrame_mouseId)\n",
    "\n",
    "        # flag to know if all the current frame mouse ids\n",
    "        # are matched to the next frame\n",
    "        valid_toSkip_flag = True\n",
    "        # get the number of unmatached mouse ids in the current frame\n",
    "        unmatched_currentFrame_Ids = []\n",
    "        for valid_currentFrame_ids, existFlags in valid_mouseId_presence.items():\n",
    "            if existFlags[1]:\n",
    "                continue\n",
    "            \n",
    "            # when not matched \n",
    "            if existFlags[0]:\n",
    "                unmatched_currentFrame_Ids.append(valid_currentFrame_ids)\n",
    "                valid_toSkip_flag = False\n",
    "\n",
    "\n",
    "        # when all the current frame mouse ids and the next frame mouse ids\n",
    "        # are matched and nothing new exist. Skip to the next frame as the current \n",
    "        # frame\n",
    "        if valid_toSkip_flag and (len(new_nextFrame_mouseIds) == 0):\n",
    "            if printing:\n",
    "                print(f\"case 1 {currentFrame_index} - {nextFrame_index}\")\n",
    "            currentFrame_index = nextFrame_index\n",
    "            continue\n",
    "        # when all the mouse ids from the current frames are matched but there\n",
    "        # is a new mouse id present in the next frame\n",
    "        # Note: this way of doing is viable here because we know 'at max' there can be only \n",
    "        # 5 mouse ids in any frame\n",
    "        elif valid_toSkip_flag and (len(new_nextFrame_mouseIds) > 0):\n",
    "            if printing:\n",
    "                print(f\"Case 2 {currentFrame_index} - {nextFrame_index}:\")\n",
    "            # for the new mouse id\n",
    "            for new_nextFrame_mouseId in new_nextFrame_mouseIds:\n",
    "                # check for the mouse id that doesn't present in the current frame\n",
    "                for valid_mouseId, existFlags in valid_mouseId_presence.items():\n",
    "                    if existFlags[0]:\n",
    "                        continue\n",
    "                    \n",
    "                    # when found set its valid existence to true\n",
    "                    valid_mouseId_presence[valid_mouseId] = (True, True)\n",
    "                    # update the next frame new mouse id to the valid non exist one\n",
    "                    detections[f'{nextFrame_index}'].update({\n",
    "                        valid_mouseId : detections[f'{nextFrame_index}'].pop(new_nextFrame_mouseId)\n",
    "                    })\n",
    "\n",
    "                    if printing:\n",
    "                        print(f\"\\t{valid_mouseId} - {new_nextFrame_mouseId}\")\n",
    "                    # To skip to the next new mouse id in the next frame\n",
    "                    break\n",
    "            \n",
    "            # Skip to the next frame as the current frame\n",
    "            currentFrame_index = nextFrame_index\n",
    "            continue\n",
    "        # when few of the mouse ids from the current frame are not matched but there\n",
    "        # are also no new mouse ids present in the next frame\n",
    "        if not(valid_toSkip_flag) and (len(new_nextFrame_mouseIds) == 0):\n",
    "            if printing:\n",
    "                print(f\"Case 3 {currentFrame_index} - {nextFrame_index}\")\n",
    "            #  check for the mouse id that doesn't have a match in the current frame\n",
    "            for valid_mouseId, existFlags in valid_mouseId_presence.items():\n",
    "                if not(existFlags[0]) or existFlags[1]:\n",
    "                    continue\n",
    "\n",
    "                # when found set its valid matched existence to true\n",
    "                valid_mouseId_presence[valid_mouseId] = (True, True)\n",
    "                # add it to the next frame \n",
    "                detections[f'{nextFrame_index}'].update({\n",
    "                        valid_mouseId : detections[f'{currentFrame_index}'][valid_mouseId]\n",
    "                    })\n",
    "                \n",
    "                if printing:\n",
    "                    print(f\"\\t{valid_mouseId}\")\n",
    "                \n",
    "            # Skip to the next frame as the current frame\n",
    "            currentFrame_index = nextFrame_index\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # set a i x j cost matrix where, \n",
    "        #   i is the number of detections in current frame\n",
    "        #   j is the number od detections in previous frame\n",
    "        cost_matrix = np.zeros(\n",
    "            (len(unmatched_currentFrame_Ids), len(new_nextFrame_mouseIds)),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        # populate the cost matrix\n",
    "        for row_index in  range(len(unmatched_currentFrame_Ids)):\n",
    "            # for every current frame unmatched mouse id \n",
    "            unmatched_currentFrame_Id = unmatched_currentFrame_Ids[row_index]\n",
    "\n",
    "            # we compute its cost with every new mouse id in the next frame\n",
    "            for col_index in range(len(new_nextFrame_mouseIds)):\n",
    "                new_nextFrame_mouseId = new_nextFrame_mouseIds[col_index]\n",
    "                \n",
    "                cost_matrix[row_index][col_index] = compute_cost(\n",
    "                    detections[f'{currentFrame_index}'][unmatched_currentFrame_Id],\n",
    "                    detections[f'{nextFrame_index}'][new_nextFrame_mouseId],\n",
    "                    scale_factor,\n",
    "                    penalty_per_missing,\n",
    "                    abs_w,\n",
    "                    abs_h,\n",
    "                    alpha,\n",
    "                    epsilon\n",
    "                )\n",
    "\n",
    "        # Best match set of unmatched current frame and next frame mouse ids\n",
    "        row_indexs, col_indexs = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "        # for every match\n",
    "        for match_index in range(len(row_indexs)):\n",
    "            # get the matched row and col index\n",
    "            matched_rowIndex = row_indexs[match_index]\n",
    "            matched_colIndex = col_indexs[match_index]\n",
    "            # get the matched id from the corresponding frames\n",
    "            unmatched_currentFrame_Id = unmatched_currentFrame_Ids[matched_rowIndex]\n",
    "            new_nextFrame_mouseId = new_nextFrame_mouseIds[matched_colIndex]\n",
    "\n",
    "            if printing:\n",
    "                print(f\"Case 4 {currentFrame_index} - {nextFrame_index}\\n\\t{unmatched_currentFrame_Id} - {new_nextFrame_mouseId}\")\n",
    "\n",
    "            # update the valid matched existence of the matched current frame\n",
    "            # mouse id\n",
    "            valid_mouseId_presence[unmatched_currentFrame_Id] = (True, True)\n",
    "\n",
    "            # If the computed cost between the two ids is less or equal to the\n",
    "            # cost thresold or the id has been stuck with the previous annotations\n",
    "            # for a long time because of a higher cost, simply update the new mouse\n",
    "            # id in the next frame with the current frame matched id.\n",
    "            stuck_condition = (stuck_ids[unmatched_currentFrame_Id][0] and stuck_ids[unmatched_currentFrame_Id][1] < releaseId_atValue)\n",
    "            if cost_matrix[matched_rowIndex][matched_colIndex] <= cost_threshold or stuck_condition:\n",
    "                detections[f'{nextFrame_index}'].update({\n",
    "                    unmatched_currentFrame_Id : detections[f'{nextFrame_index}'].pop(new_nextFrame_mouseId)\n",
    "                })\n",
    "\n",
    "                if stuck_condition:\n",
    "                    if printing:\n",
    "                        print(f\"Stucked id {unmatched_currentFrame_Id} released at frame {nextFrame_index} of {vid_name}.\")\n",
    "                    # update the stuck id status to free\n",
    "                    stuck_ids[unmatched_currentFrame_Id] = (False, 0)\n",
    "            else: \n",
    "                # otherwise, remove the new mouse id and its data in the next frame and simply replace it with \n",
    "                # current frame matched mouse id and its data.\n",
    "                detections[f'{nextFrame_index}'].pop(new_nextFrame_mouseId)\n",
    "\n",
    "                detections[f'{nextFrame_index}'].update({\n",
    "                    unmatched_currentFrame_Id : detections[f'{currentFrame_index}'][unmatched_currentFrame_Id]\n",
    "                })\n",
    "\n",
    "                if printing:\n",
    "                    print(f\"Id {unmatched_currentFrame_Id} stucked at frame {nextFrame_index} of {vid_name}.\")\n",
    "                # update the stuck id status and increment it's stuck time by 1\n",
    "                stuck_ids[unmatched_currentFrame_Id] = (True, stuck_ids[unmatched_currentFrame_Id][1]+1)\n",
    "\n",
    "\n",
    "        # check for the mouse id that doesn't have a match in the current frame,\n",
    "        # even after the cost comparision\n",
    "        for valid_mouseId, existFlags in valid_mouseId_presence.items():\n",
    "            if not(existFlags[0]) or existFlags[1]:\n",
    "                continue\n",
    "\n",
    "            # updates its valid matched existence to true\n",
    "            valid_mouseId_presence[valid_mouseId] = (True, True)\n",
    "            # add it to the next frame \n",
    "            detections[f'{nextFrame_index}'].update({\n",
    "                    valid_mouseId : detections[f'{currentFrame_index}'][valid_mouseId]\n",
    "                })\n",
    "            \n",
    "            # Skip to the next frame as the current frame\n",
    "            if printing:\n",
    "                print(f\"case 5 {currentFrame_index} - {nextFrame_index}\\n\\t {valid_mouseId}\")\n",
    "\n",
    "        # for every new mouse id we say in the next ffame\n",
    "        for new_nextFrame_mouseId in new_nextFrame_mouseIds:\n",
    "            # check there is any new mouse id in the next frame that did not get any match\n",
    "            # with the cost comparision check\n",
    "            if not(new_nextFrame_mouseId in detections[f'{nextFrame_index}']):\n",
    "                continue\n",
    "            \n",
    "            # look for the non exist valid mouse id in the current frame\n",
    "            for valid_mouseId, existFlags in valid_mouseId_presence.items():\n",
    "                if existFlags[0]:\n",
    "                    continue\n",
    "                \n",
    "                # when found set its valid existence to true\n",
    "                valid_mouseId_presence[valid_mouseId] = (True, True)\n",
    "                # update the next frame new mouse id to the valid non exist one\n",
    "                detections[f'{nextFrame_index}'].update({\n",
    "                    valid_mouseId : detections[f'{nextFrame_index}'].pop(new_nextFrame_mouseId)\n",
    "                })\n",
    "\n",
    "                if printing:\n",
    "                    print(f\"Case 6 {currentFrame_index} - {nextFrame_index}\\n\\t{valid_mouseId} - {new_nextFrame_mouseId}\")\n",
    "                # To skip to the next new mouse id in the next frame\n",
    "                break\n",
    "\n",
    "        # go to next frame\n",
    "        currentFrame_index = nextFrame_index\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_annotations_on_video(input_video, annotations, color_box, color_kpt, output_video=\"output.mp4\", discard=(False, [])):\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "    # Retrieve video properties\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Define codec and create VideoWriter to save the output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # or 'XVID'/'avc1' etc.\n",
    "    out    = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_index = 1  # or 0, depending on how your annotations are keyed\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # no more frames in video\n",
    "        \n",
    "        if f\"{frame_index}\" in annotations:\n",
    "            try:\n",
    "                # Get all mice info for this frame\n",
    "                for mouse_id, mouse_data in annotations[f\"{frame_index}\"].items():\n",
    "\n",
    "                    if discard[0] and (int(mouse_id) in discard[1]):\n",
    "                        continue\n",
    "\n",
    "                    # Extract bounding box\n",
    "                    bbox = mouse_data['bbox']\n",
    "                    x1, y1 = int(bbox['x1']), int(bbox['y1'])\n",
    "                    x2, y2 = int(bbox['x2']), int(bbox['y2'])\n",
    "\n",
    "                    # Draw the bounding box\n",
    "                    # color_box = (0, 255, 255)  # e.g. yellow\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color_box[mouse_id], 2)\n",
    "                    # cv2.rectangle(frame, (x1, y1), (x2, y2), color_box[int(mouse_id)], 2)\n",
    "\n",
    "\n",
    "                    # (Optional) Label the mouse ID\n",
    "                    cv2.putText(frame, f\"Mouse {mouse_id}\", (x1, y1 - 5),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_box[mouse_id], 2)\n",
    "                    # cv2.putText(frame, f\"Mouse {mouse_id}\", (x1, y1 - 5),\n",
    "                    #             cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_box[int(mouse_id)], 2)\n",
    "\n",
    "                    # Draw each keypoint\n",
    "                    keypoints = mouse_data['keypoints']\n",
    "                    for kpt_name, (kx, ky, conf) in keypoints.items():\n",
    "                        # conf is a confidence score you can use if needed\n",
    "                        kx, ky = int(kx), int(ky)\n",
    "                        # color_kpt = (0, 255, 0)  # e.g. green\n",
    "                        cv2.circle(frame, (kx, ky), 4, color_kpt[kpt_name], -1)\n",
    "\n",
    "                        # (Optional) label the keypoint name\n",
    "                        cv2.putText(frame, kpt_name, (kx+5, ky),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_kpt[kpt_name], 1)\n",
    "                        \n",
    "            except Exception as error:\n",
    "                print(f\"Error - Frame {frame_index}\")\n",
    "\n",
    "        # Write the modified frame to output video\n",
    "        out.write(frame)\n",
    "\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Finished writing annotated video:\", output_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedAnnotated_vids_dir = \"\"\n",
    "vids_predictionOn_path = \"\"\n",
    "output_dir = \"\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [01:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing annotated video: /mnt/c/Users/karti/chest/CNR/projects/data/neurocig/vids/results/cycle_9/track_plus/Gabbia2-D1-Cig(1)-pre/Gabbia2-D1-Cig(1)-pre.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for vid_name in tqdm(os.listdir(vids_predictionOn_path)):\n",
    "    if not vid_name.endswith('.mp4'):\n",
    "        continue\n",
    "        \n",
    "    orig_vidPath = os.path.join(vids_predictionOn_path, vid_name)\n",
    "\n",
    "    predicted_labelsPath = os.path.join(predictedAnnotated_vids_dir, f'{vid_name.removesuffix(\".mp4\")}/labels')\n",
    "\n",
    "    output_tracked_vidPath = os.path.join(output_dir, vid_name.removesuffix(\".mp4\"))\n",
    "    os.makedirs(output_tracked_vidPath, exist_ok=True)\n",
    "\n",
    "    img_w, img_h = get_video_resolution(orig_vidPath)\n",
    "\n",
    "    # get the number of frames in that videos\n",
    "    nOf_fames = get_nOf_frames(orig_vidPath)\n",
    "\n",
    "    # dict { frame_idx: [ { 'bbox':(x,y,w,h), 'keypoints':... }, ... ] }\n",
    "    detections = {}\n",
    "\n",
    "    mAnnotated_flag = False\n",
    "    visiblePercentage = 1.0\n",
    "    for predicted_label in os.listdir(predicted_labelsPath):\n",
    "        if predicted_label.endswith('.txt'):\n",
    "            txt_path = os.path.join(predicted_labelsPath, predicted_label)\n",
    "            temp_holder = predicted_label.split('_')\n",
    "            frame_index = f\"{int(temp_holder[len(temp_holder)-1].split('.')[0])}\"\n",
    "            detection, valid_detection = yolo_txt_to_annotation_json(\n",
    "                txt_path,\n",
    "                frame_index,\n",
    "                img_w,\n",
    "                img_h,\n",
    "                mAnnotated_flag,\n",
    "                visiblePercentage,\n",
    "                [\"nose\", \"earL\", \"earR\", \"tailB\"],\n",
    "                tracked=True\n",
    "            )\n",
    "\n",
    "        if valid_detection:\n",
    "            detections.update(detection)\n",
    "    # sort based on frame index\n",
    "    detections = dict(sorted(detections.items()))\n",
    "    save_metadata(output_tracked_vidPath, 'detections.json', detections)\n",
    "\n",
    "    detections = load_metadata(output_tracked_vidPath, f'detections.json')\n",
    "\n",
    "    # perform tracking\n",
    "    framesSkip_limit = 30\n",
    "    scale_factor = 0.15\n",
    "    penalty_per_missing = 100\n",
    "    alpha = 0.75\n",
    "    epsilon = 1e-6\n",
    "    cost_threshold = -0.90\n",
    "    releaseId_atValue = 61\n",
    "    printing = False\n",
    "    tracked_detections = track(\n",
    "        vid_name,\n",
    "        nOf_fames,\n",
    "        detections,\n",
    "        framesSkip_limit,\n",
    "        scale_factor,\n",
    "        penalty_per_missing,\n",
    "        img_w, img_h, alpha,\n",
    "        epsilon,\n",
    "        cost_threshold,\n",
    "        releaseId_atValue,\n",
    "        printing\n",
    "    )\n",
    "    save_metadata(output_tracked_vidPath, f'tracked_annotations.json', tracked_detections)\n",
    "\n",
    "    FinalVideo_path = os.path.join(output_tracked_vidPath, vid_name)\n",
    "    color_box = {\n",
    "        '1' : (0, 0, 255),\n",
    "        '2' : (0, 191, 255),\n",
    "        '3' : (0, 255, 0),\n",
    "        '4' : (255, 255, 0),\n",
    "        '5' : (255, 0, 191)\n",
    "    }\n",
    "    color_kpt = {\n",
    "        'nose' : (0, 255, 255),\n",
    "        'earL' : (255, 102, 102),\n",
    "        'earR' : (140, 102, 255),\n",
    "        'tailB' : (0, 128, 255)\n",
    "    }\n",
    "    discard = (False, [])\n",
    "\n",
    "    overlay_annotations_on_video(orig_vidPath,\n",
    "        tracked_detections,\n",
    "        color_box,\n",
    "        color_kpt,\n",
    "        FinalVideo_path,\n",
    "        discard\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BehavTrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
