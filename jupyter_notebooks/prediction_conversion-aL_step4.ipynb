{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(source_dir, metadata_filename):\n",
    "    metadata_filePath = os.path.join(source_dir, metadata_filename)\n",
    "\n",
    "    with open(metadata_filePath, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata(output_dir, metadata_filename, metadata):\n",
    "    metadata_outFilePath = os.path.join(output_dir, metadata_filename)\n",
    "\n",
    "    with open(metadata_outFilePath, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyframes(split):\n",
    "    # destination path for the split frame\n",
    "    out_path = os.path.join(split[2][1], split[0][0])\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    # save the metadata at the output\n",
    "    save_metadata(split[2][1], split[0][1], split[1][0])\n",
    "\n",
    "    if split[1][1]:\n",
    "        for data in split[1][0]:\n",
    "            frame_name = os.path.basename(data['image_path'])\n",
    "            # src frame path\n",
    "            src_framePath = os.path.join(split[2][0], frame_name)\n",
    "            out_framePath = os.path.join(out_path, frame_name)\n",
    "            # copy\n",
    "            shutil.copy2(src_framePath, out_framePath)\n",
    "\n",
    "    print(f\"Copy complete for the split {split[0][1]} with images - {split[1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.width, img.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPointInBBox(x, y, x1, y1, x2, y2):\n",
    "  return (\n",
    "    x >= x1 and x <= x2 and\n",
    "    y >= y1 and y <= y2\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_txt_to_annotation_json(\n",
    "    txt_path, \n",
    "    image_filename,   # \"image_filename.jpg\"\n",
    "    image_width, \n",
    "    image_height,\n",
    "    keypoint_names=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads a YOLO-like .txt (with bbox + 4 keypoints in normalized coords),\n",
    "    and returns a dictionary in the original annotation style:\n",
    "\n",
    "    {\n",
    "      \"image_filename\": [\n",
    "        {\n",
    "          \"bbox\": {\"x1\":..., \"y1\":..., \"x2\":..., \"y2\":...},\n",
    "          \"keypoints\": {\n",
    "            \"nose\":  [...],\n",
    "            \"earL\":  [...],\n",
    "            \"earR\":  [...],\n",
    "            \"tailB\": [...]\n",
    "          }\n",
    "        },\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    if keypoint_names is None:\n",
    "        # You can change the order or number of keypoints as needed:\n",
    "        keypoint_names = [\"nose\", \"earL\", \"earR\", \"tailB\"]\n",
    "\n",
    "    annotations = {image_filename: []}\n",
    "\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        tokens = line.split()\n",
    "        # The first 5 tokens are class_id, x_center, y_center, w, h\n",
    "        class_id    = int(tokens[0])\n",
    "        x_center_n  = float(tokens[1])\n",
    "        y_center_n  = float(tokens[2])\n",
    "        w_n         = float(tokens[3])\n",
    "        h_n         = float(tokens[4])\n",
    "\n",
    "        # Denormalize bounding box\n",
    "        x_center = x_center_n * image_width\n",
    "        y_center = y_center_n * image_height\n",
    "        w        = w_n * image_width\n",
    "        h        = h_n * image_height\n",
    "\n",
    "        x1 = x_center - w / 2\n",
    "        y1 = y_center - h / 2\n",
    "        x2 = x_center + w / 2\n",
    "        y2 = y_center + h / 2\n",
    "\n",
    "        if (x1 == x2 or y1 == y2):\n",
    "            continue\n",
    "\n",
    "        # Next tokens: each keypoint has x_kpt_n, y_kpt_n, v_kpt\n",
    "        # For 4 keypoints, that's 12 tokens, starting at index = 5\n",
    "        keypoints_dict = {}\n",
    "        num_kpts = len(keypoint_names)\n",
    "        \n",
    "        # i.e. for 4 keypoints, range(4) => 0..3\n",
    "        for i in range(num_kpts):\n",
    "            x_kpt_n = float(tokens[5 + 3*i])\n",
    "            y_kpt_n = float(tokens[5 + 3*i + 1])\n",
    "            v_kpt   = float(tokens[5 + 3*i + 2])\n",
    "\n",
    "            # denormalize\n",
    "            x_kpt = x_kpt_n * image_width\n",
    "            y_kpt = y_kpt_n * image_height\n",
    "\n",
    "            if not(isPointInBBox(x_kpt, y_kpt, x1, y1, x2, y2)):\n",
    "                continue\n",
    "            \n",
    "            kpt_name = keypoint_names[i]\n",
    "            \n",
    "            keypoints_dict[kpt_name] = [x_kpt, y_kpt, 2 if v_kpt > 0.8 else 1]\n",
    "\n",
    "        annotations[image_filename].append({\n",
    "            \"bbox\": {\n",
    "                \"x1\": x1,\n",
    "                \"y1\": y1,\n",
    "                \"x2\": x2,\n",
    "                \"y2\": y2\n",
    "            },\n",
    "            \"keypoints\": keypoints_dict,\n",
    "            \"mAnnotated\": False\n",
    "        })\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs' path\n",
    "source_dir = \"/mnt/c/Users/karti/chest/CNR/projects/data/neurocig/frames\"\n",
    "activeLearning_dir = \"/mnt/c/Users/karti/chest/CNR/projects/data/neurocig/stratifySplit_frames/activeLearning\"\n",
    "predict_dir = \"/mnt/c/Users/karti/chest/CNR/projects/data/neurocig/stratifySplit_frames/activeLearning/predict\"\n",
    "\n",
    "# path to manual annotated frames and its json\n",
    "annotations_dir = os.path.join(activeLearning_dir, \"annotations\")\n",
    "annotation_json = \"annotation.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_metadata = load_metadata(activeLearning_dir, \"predict.json\")\n",
    "predict_metadata\n",
    "annotation_metadata = load_metadata(activeLearning_dir, \"annotations_metadata.json\")\n",
    "annotation_metadata.extend(predict_metadata)\n",
    "split_data_combine = (\n",
    "        ('annotations', 'annotations_metadata.json'),\n",
    "        (annotation_metadata, True),\n",
    "        (source_dir, activeLearning_dir)\n",
    "    )\n",
    "\n",
    "copyframes(split_data_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedAnnotated_json = load_metadata(annotations_dir, annotation_json)\n",
    "for label in os.listdir(predict_dir):\n",
    "    if label.endswith(\".txt\"):\n",
    "        label_path = os.path.join(predict_dir, label)\n",
    "\n",
    "        image_name = label.replace('txt', 'jpg')\n",
    "        img_path = os.path.join(predict_dir, image_name)\n",
    "        img_w, img_h = get_image_size(img_path)\n",
    "        \n",
    "        predictions = yolo_txt_to_annotation_json(label_path, image_name,img_w, img_h, [\"nose\", \"earL\", \"earR\", \"tailB\"])\n",
    "        combinedAnnotated_json.update(predictions)\n",
    "\n",
    "save_metadata(annotations_dir, \"annotation.json\", combinedAnnotated_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BehavTrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
