{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(source_dir, metadata_filename):\n",
    "    metadata_filePath = os.path.join(source_dir, metadata_filename)\n",
    "\n",
    "    with open(metadata_filePath, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performSplit(metadata, split_ratio):\n",
    "    clusters = [entry['cluster'] for entry in metadata]\n",
    "    \n",
    "    activeLearning_data, prediction_data = train_test_split(\n",
    "        metadata,\n",
    "        test_size=split_ratio,\n",
    "        random_state=42,\n",
    "        stratify=clusters  # stratify \n",
    "        )\n",
    "    \n",
    "    return activeLearning_data, prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCluster_ratio(data):\n",
    "    # Count the number of frames per cluster\n",
    "    cluster_counts = Counter(entry['cluster'] for entry in data)\n",
    "    # Calculate total number of frames\n",
    "    total_frames = len(data)\n",
    "    # Print cluster percentages\n",
    "    for cluster_id, count in cluster_counts.items():\n",
    "        percentage = (count / total_frames) * 100\n",
    "        print(f\"Cluster {cluster_id}: {count} frames ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDetails(metadata, split_data):\n",
    "    print(\"#############\")\n",
    "    print(f\"Total frames: {len(metadata)}\")\n",
    "    getCluster_ratio(metadata)\n",
    "    print(\"\\t#############\")\n",
    "    for split in split_data:\n",
    "        percentage = (len(split[1][0])/len(metadata))*100\n",
    "        print(f\"{split[0][1]} split: {len(split[1][0])} ({percentage:.2f}%)\")\n",
    "        getCluster_ratio(split[1][0])\n",
    "        print(\"\\t#############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata(output_dir, metadata_filename, metadata):\n",
    "    metadata_outFilePath = os.path.join(output_dir, metadata_filename)\n",
    "\n",
    "    with open(metadata_outFilePath, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyframes(split):\n",
    "    # destination path for the split frame\n",
    "    out_path = os.path.join(split[2][1], split[0][0])\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    # save the metadata at the output\n",
    "    save_metadata(split[2][1], split[0][1], split[1][0])\n",
    "\n",
    "    if split[1][1]:\n",
    "        for data in split[1][0]:\n",
    "            frame_name = os.path.basename(data['image_path'])\n",
    "            # src frame path\n",
    "            src_framePath = os.path.join(split[2][0], frame_name)\n",
    "            out_framePath = os.path.join(out_path, frame_name)\n",
    "            # copy\n",
    "            shutil.copy2(src_framePath, out_framePath)\n",
    "\n",
    "    print(f\"Copy complete for the split {split[0][1]} with images - {split[1][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirs' path\n",
    "source_dir = \"/mnt/c/Users/karti/chest/CNR/projects/data/neurocig/frames\"\n",
    "output_dir = \"/mnt/c/Users/karti/chest/CNR/projects/data/neurocig/stratifySplit_frames\"\n",
    "activeLearning_dir = \"/mnt/c/Users/karti/chest/CNR/projects/data/neurocig/stratifySplit_frames/activeLearning\"\n",
    "metadata_filename_al = \"activeLearning.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of initial frames of manuel annotation\n",
    "intialN_annotatonData = 100\n",
    "\n",
    "# load the active learning frames metadata\n",
    "activeLearning_metadata = load_metadata(activeLearning_dir, metadata_filename_al)\n",
    "\n",
    "# calculate the split ratio respective to intialN_annotatonData\n",
    "split_ratio_aL = round(((intialN_annotatonData/len(activeLearning_metadata))*100)/100, 3)\n",
    "\n",
    "# annotation split\n",
    "activeLearning_metadata_new, annotation_metadata = performSplit(activeLearning_metadata, split_ratio_aL)\n",
    "\n",
    "split_data_aL = (\n",
    "        ('activeLearning', 'activeLearning.json'),\n",
    "        (activeLearning_metadata_new, False),\n",
    "        (source_dir, output_dir)\n",
    "    )\n",
    "\n",
    "split_data_annotations =   (\n",
    "        ('annotations', 'annotations_metadata.json'),\n",
    "        (annotation_metadata, True),\n",
    "        (source_dir, activeLearning_dir)\n",
    "    )\n",
    "\n",
    "printDetails(activeLearning_metadata, [split_data_aL, split_data_annotations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_percentage = 30\n",
    "nOf_annotations = float((prediction_percentage*len(annotation_metadata))/100)\n",
    "split_ratio_predict = round(((nOf_annotations/len(activeLearning_metadata_new))*100)/100, 3)\n",
    "\n",
    "# annotation split\n",
    "activeLearning_metadata_updated, predict_metadata = performSplit(activeLearning_metadata_new, split_ratio_predict)\n",
    "\n",
    "split_data_aL = (\n",
    "        ('activeLearning', 'activeLearning.json'),\n",
    "        (activeLearning_metadata_updated, False),\n",
    "        (source_dir, output_dir)\n",
    "    )\n",
    "\n",
    "split_data_predict =   (\n",
    "        ('predict', 'predict.json'),\n",
    "        (predict_metadata, True),\n",
    "        (source_dir, activeLearning_dir)\n",
    "    )\n",
    "\n",
    "printDetails(activeLearning_metadata_new, [split_data_aL, split_data_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio_annotation = 0.15\n",
    "\n",
    "# train val split\n",
    "train_metadata, val_metadata = performSplit(annotation_metadata, split_ratio_annotation)\n",
    "\n",
    "split_data_train = (\n",
    "        ('train', 'train.json'),\n",
    "        (train_metadata, False),\n",
    "        (source_dir, activeLearning_dir)\n",
    "    )\n",
    "\n",
    "split_data_val =   (\n",
    "        ('val', 'val.json'),\n",
    "        (val_metadata, False),\n",
    "        (source_dir, activeLearning_dir)\n",
    "    )\n",
    "\n",
    "printDetails(annotation_metadata, [split_data_train, split_data_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_is = [split_data_aL, split_data_annotations, split_data_train, split_data_val, split_data_predict]\n",
    "\n",
    "for split in split_data_is:\n",
    "    copyframes(split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BehavTrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
